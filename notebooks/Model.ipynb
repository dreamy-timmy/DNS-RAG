{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "with open('api_key.txt', 'r') as f:\n",
    "    key = f.read()\n",
    "\n",
    "os.environ['GIGACHAT_API_ACCESS_KEY'] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gunte\\AppData\\Local\\Temp\\ipykernel_18032\\3995579388.py:24: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "C:\\Users\\gunte\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x1edcae18d10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter \n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "file_paths = [\n",
    "    'docs/laptops1.json',\n",
    "    'docs/raw_recomm_papers_1.txt',\n",
    "    'docs/raw_recomm_papers_2.txt',\n",
    "    'docs/raw_recomm_papers_3.txt'\n",
    "]\n",
    "\n",
    "# Load each file and store the results in a list\n",
    "documents = []\n",
    "for file_path in file_paths:\n",
    "    loader = TextLoader(file_path, encoding='utf-8')  # Specify the encoding\n",
    "    documents.extend(loader.load())\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "db = Chroma.from_documents(docs, embedding_function)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'docs/laptops1.json'}, page_content='},\\n                \"Дополнительные характеристики\": {\\n                    \"Гарантия\": \"12 мес.\"\\n                }\\n            }\\n        }\\n    ]\\n]'),\n",
       " Document(metadata={'source': 'docs/laptops1.json'}, page_content='},\\n                \"Операционная система ноутбука\": {\\n                    \"Операционная система\": \"Free DOS\"\\n                },\\n                \"Назначение\": {\\n                    \"Для учебы\": \"да\",\\n                    \"Для работы\": \"да\"\\n                },\\n                \"Мультимедийные особенности\": {\\n                    \"Для работы\": \"встроенная\",\\n                    \"Разрешение\": \"0.9 Мп\",\\n                    \"Тип веб-камеры\": \"со шторкой\",'),\n",
       " Document(metadata={'source': 'docs/laptops1.json'}, page_content='},\\n                \"Операционная система ноутбука\": {\\n                    \"Операционная система\": \"Free DOS\"\\n                },\\n                \"Назначение\": {\\n                    \"Для учебы\": \"да\",\\n                    \"Для работы\": \"да\"\\n                },\\n                \"Мультимедийные особенности\": {\\n                    \"Для работы\": \"встроенная\",\\n                    \"Разъем\": \"комбинированный разъем\",\\n                    \"Акустическая\": \"стереодинамики\"\\n                },'),\n",
       " Document(metadata={'source': 'docs/laptops1.json'}, page_content='},\\n                \"Назначение\": {\\n                    \"Для учебы\": \"да\",\\n                    \"Для работы\": \"да\"\\n                },\\n                \"Мультимедийные особенности\": {\\n                    \"Для работы\": \"встроенная\",\\n                    \"Разрешение\": \"0.9 Мп\",\\n                    \"Тип веб-камеры\": \"со шторкой\",\\n                    \"Разъем\": \"комбинированный разъем\",\\n                    \"Акустическая\": \"стереодинамики\"\\n                },')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever()\n",
    "retrieved_docs = retriever.invoke(\"Ноутбук для учёбы\")\n",
    "\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models.gigachat import GigaChat\n",
    "from langchain.chains import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gunte\\AppData\\Local\\Temp\\ipykernel_18032\\4017348131.py:1: LangChainDeprecationWarning: The class `GigaChat` was deprecated in LangChain 0.3.5 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-gigachat package and should be used instead. To use it run `pip install -U :class:`~langchain-gigachat` and import as `from :class:`~langchain_gigachat import GigaChat``.\n",
      "  llm = GigaChat(\n"
     ]
    }
   ],
   "source": [
    "llm = GigaChat(\n",
    "    credentials=os.environ['GIGACHAT_API_ACCESS_KEY'],\n",
    "    model=\"GigaChat\",\n",
    "    verify_ssl_certs=False,\n",
    "    profanity_check=False,\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(''' Ты - консультант в техническом интернет-магазине \\\n",
    "                                          Ответь на вопрос пользователя. \\\n",
    "Используй при этом информацию из контекста. Если в контексте нет \\\n",
    "информации для ответа, попроси пользователя уточнить необходимые детали.\n",
    "Контекст: {context}\n",
    "Вопрос: {input}\n",
    "Ответ:'''\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chain = create_stuff_documents_chain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Какой лучше ноутбук подойдёт для пожилого человека на пенсии?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "question2 = \"Можешь пожалуйста дополнить ответ на предыдущий вопрос, учитывая, что у этого человека также есть внуки, которые могут приходить в гости и иногда играть?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "question3 = \"Учитывая всё выше сказанное добавлю, что стоиомсть ноутбука не должна превышать 35 тыс рублей, какие модели ты можешь посоветовать при таком раскладе?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = retrieval_chain.invoke({'input': question3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(question+'\\n\\n')\n",
    "    \n",
    "    f.write(result['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
